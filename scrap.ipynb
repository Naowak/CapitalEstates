{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load communes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "\n",
    "def load_data():\n",
    "    data = []\n",
    "    with open('data/communes.json') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "def format_url_ville_data(feature, kind=\"log\"):\n",
    "\n",
    "    # Récupération du nom et du code de la commune\n",
    "    name, code = feature['name'], feature['id']\n",
    "    \n",
    "    # Suppression des accents\n",
    "    name = ''.join((c for c in unicodedata.normalize('NFD', name) if unicodedata.category(c) != 'Mn'))\n",
    "\n",
    "    # Remplacement des espaces et autres caractères non alphanumériques par des tirets\n",
    "    name = name.replace(\" \", \"-\")\n",
    "    name = name.replace(\"'\", \"-\")\n",
    "    name = name.replace(\"œ\", \"oe\")\n",
    "    name = ''.join(e for e in name if e.isalnum() or e == '-')\n",
    "\n",
    "    # Statistique type\n",
    "    kinds = {\n",
    "        \"log\": \"logement\",\n",
    "        \"pop\": \"nombre-d-habitants\"\n",
    "    }\n",
    "\n",
    "    return f\"https://ville-data.com/{kinds[kind]}/{name}-33-{code}\"\n",
    "\n",
    "\n",
    "\n",
    "communes = pd.DataFrame(load_data())\n",
    "communes['url_log'] = communes.apply(lambda x: format_url_ville_data(x, \"log\"), axis=1)\n",
    "communes['url_pop'] = communes.apply(lambda x: format_url_ville_data(x, \"pop\"), axis=1)\n",
    "communes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrap housing and population data from the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "# Open the browser\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://ville-data.com/\")\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "# Consent ville-data.com cookies\n",
    "query = '//button[@class=\"fc-button fc-cta-consent fc-primary-button\"]'\n",
    "buttons = driver.find_element(By.XPATH, query)\n",
    "buttons.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrap population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "import re \n",
    "import time\n",
    "\n",
    "def extract_pop():\n",
    "    # Find number of housing\n",
    "    try:\n",
    "        query = '//div[contains(@id, \"Population d\")]'\n",
    "        text = driver.find_element(By.XPATH, query).find_element(By.TAG_NAME, 'p').text\n",
    "        regex = r'Il y a (\\d+(?:\\s*\\d+)*) habitants'\n",
    "        match = re.search(regex, text)\n",
    "        population = int(match.group(1).replace(' ', ''))\n",
    "    except:\n",
    "        population = None\n",
    "\n",
    "    return {\n",
    "        'population': population\n",
    "    }\n",
    "\n",
    "def update_pop(row):\n",
    "    driver.get(row['url_pop'])\n",
    "    time.sleep(1)\n",
    "    values = extract_pop()\n",
    "    for key, value in values.items():\n",
    "        row[key] = value\n",
    "    return row\n",
    "\n",
    "\n",
    "# Update values with selenium\n",
    "communes = communes.apply(update_pop, axis=1)\n",
    "communes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrap housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "import re \n",
    "import time\n",
    "\n",
    "def extract_log():\n",
    "    # Find number of housing\n",
    "    try:\n",
    "        query = '//div[contains(@id, \"Nombre de logements à\")]'\n",
    "        text = driver.find_element(By.XPATH, query).find_element(By.TAG_NAME, 'p').text\n",
    "        regex = r'(\\d+(?:\\s*\\d+)*)\\s*logements'\n",
    "        match = re.search(regex, text)\n",
    "        number_of_housing = int(match.group(1).replace(' ', ''))\n",
    "    except:\n",
    "        number_of_housing = None\n",
    "\n",
    "    # Find number of house\n",
    "    try:\n",
    "        query = '//div[contains(@id, \"Nombre de maisons à\")]'\n",
    "        text = driver.find_element(By.XPATH, query).find_element(By.TAG_NAME, 'p').text\n",
    "        regex = r'(\\d+(?:\\s*\\d+)*)\\s*maisons'\n",
    "        match = re.search(regex, text)\n",
    "        number_of_house = int(match.group(1).replace(' ', ''))\n",
    "    except:\n",
    "        number_of_house = None\n",
    "\n",
    "    # Find number of apartment\n",
    "    try:\n",
    "        query = '//div[contains(@id, \"Nombre d\\'appartements à\")]'\n",
    "        text = driver.find_element(By.XPATH, query).find_element(By.TAG_NAME, 'p').text\n",
    "        regex = r'(\\d+(?:\\s*\\d+)*)\\s*appartements'\n",
    "        match = re.search(regex, text)\n",
    "        number_of_apartment = int(match.group(1).replace(' ', ''))\n",
    "    except:\n",
    "        number_of_apartment = None\n",
    "\n",
    "    # Logement quality\n",
    "    try:\n",
    "        query = '//div[contains(@id, \"Qualité des logements à\")]'\n",
    "        text = driver.find_element(By.XPATH, query).find_element(By.TAG_NAME, 'p').text\n",
    "\n",
    "        match_total = re.search(r'(\\d+(?:\\s*\\d+)*)\\s*logements.*?résidence principale', text)\n",
    "        match_t1 = re.search(r'(\\d+(?:\\s*\\d+)*)\\s*logements de 1 pièce', text)\n",
    "        match_t2 = re.search(r'(\\d+(?:\\s*\\d+)*)\\s*logements de 2 pièces', text)\n",
    "        match_t3 = re.search(r'(\\d+(?:\\s*\\d+)*)\\s*résidences principales de 3 pièces', text)\n",
    "        match_t4 = re.search(r'(\\d+(?:\\s*\\d+)*)\\s*logements de 4 pièces', text)\n",
    "        match_t5_plus = re.search(r'(\\d+(?:\\s*\\d+)*)\\s*logements de 5 pièces ou plus', text)\n",
    "\n",
    "        total_logements = int(match_total.group(1).replace(\" \", \"\")) if match_total else None\n",
    "        t1_logements = int(match_t1.group(1).replace(\" \", \"\")) if match_t1 else None\n",
    "        t2_logements = int(match_t2.group(1).replace(\" \", \"\")) if match_t2 else None\n",
    "        t3_logements = int(match_t3.group(1).replace(\" \", \"\")) if match_t3 else None\n",
    "        t4_logements = int(match_t4.group(1).replace(\" \", \"\")) if match_t4 else None\n",
    "        t5_plus_logements = int(match_t5_plus.group(1).replace(\" \", \"\")) if match_t5_plus else None\n",
    "    except:\n",
    "        total_logements = None\n",
    "        t1_logements = None\n",
    "        t2_logements = None\n",
    "        t3_logements = None\n",
    "        t4_logements = None\n",
    "        t5_plus_logements = None\n",
    "\n",
    "    return {\n",
    "        'housing': number_of_housing,\n",
    "        'house': number_of_house,\n",
    "        'apartment': number_of_apartment,\n",
    "        'principal': total_logements,\n",
    "        't1': t1_logements,\n",
    "        't2': t2_logements,\n",
    "        't3': t3_logements,\n",
    "        't4': t4_logements,\n",
    "        't5+': t5_plus_logements\n",
    "    }\n",
    "\n",
    "def update_log(row):\n",
    "    driver.get(row['url_log'])\n",
    "    time.sleep(1)\n",
    "    values = extract_log()\n",
    "    for key, value in values.items():\n",
    "        row[key] = value\n",
    "    return row\n",
    "\n",
    "\n",
    "# Update values with selenium\n",
    "communes = communes.apply(update_log, axis=1)\n",
    "communes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the driver, not needed anymore\n",
    "driver.close()\n",
    "\n",
    "# Fill no apartment and house with 0\n",
    "communes.apartment.fillna(0, inplace=True)\n",
    "communes.house.fillna(0, inplace=True)\n",
    "\n",
    "# Fill no t1, t2, t3, t4, t5+ with 0\n",
    "columns = ['t1', 't2', 't3', 't4', 't5+']\n",
    "communes[columns] = communes[columns].fillna(0)\n",
    "\n",
    "# Fill no housing with sum of apartment and house\n",
    "index = communes[communes.housing.isna()].index\n",
    "communes.loc[index, 'housing'] = communes.loc[index, 'apartment'] + communes.loc[index, 'house']\n",
    "\n",
    "# If no house, and no apartment, fill with estimate mean\n",
    "index = communes[(communes.house == 0) & (communes.apartment == 0)].index\n",
    "percent_house = communes.house.sum() / communes.housing.sum()\n",
    "communes.loc[index, 'house'] = communes.loc[index, 'housing'] * percent_house\n",
    "communes.loc[index, 'apartment'] = communes.loc[index, 'housing'] * (1 - percent_house)\n",
    "\n",
    "# Convert columns to int\n",
    "columns = ['id', 'population', 'housing', 'house', 'apartment', 'principal', 't1', 't2', 't3', 't4', 't5+']\n",
    "communes[columns] = communes[columns].astype(int)\n",
    "\n",
    "# house & apartment in the website are count only for principal residence\n",
    "# Adjust number of house & apartment to consider even non principal residence (estimate)\n",
    "columns = ['t1', 't2', 't3', 't4', 't5+']\n",
    "for col in columns:\n",
    "    communes[col] = (communes[col] * communes['housing'] / communes['principal']).round().astype(int)\n",
    "\n",
    "# Drop url column\n",
    "communes.drop(columns=['url_log'], inplace=True)\n",
    "communes.drop(columns=['url_pop'], inplace=True)\n",
    "\n",
    "communes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communes.to_json('data/communes-housing.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load DVF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "columns = [\n",
    "    'Nature mutation', \n",
    "    'Valeur fonciere',\n",
    "    'Code postal',\n",
    "    'Commune', \n",
    "    'Code departement', \n",
    "    'Code commune',\n",
    "    'Section', \n",
    "    'No plan', \n",
    "    'Type local',\n",
    "    'Surface reelle bati', \n",
    "    'Nombre pieces principales'\n",
    "]\n",
    "\n",
    "# Load dvfs\n",
    "dvf = pd.concat([\n",
    "    pd.read_csv('data/dvf2022.txt', sep='|', low_memory=False),\n",
    "    pd.read_csv('data/dvf2021.txt', sep='|', low_memory=False),\n",
    "    pd.read_csv('data/dvf2020.txt', sep='|', low_memory=False),\n",
    "    pd.read_csv('data/dvf2019.txt', sep='|', low_memory=False),\n",
    "    pd.read_csv('data/dvf2018.txt', sep='|', low_memory=False),\n",
    "])\n",
    "\n",
    "\n",
    "# Open DF and clean it\n",
    "dvf = dvf[dvf['Type local'].isin(['Appartement', 'Maison'])]\n",
    "dvf = dvf[dvf['Surface reelle bati'].isna() == False]\n",
    "dvf = dvf.reset_index(drop=True)\n",
    "dvf = dvf[columns]\n",
    "\n",
    "# Keep only selected communes in departement\n",
    "CODE_DEP = 33\n",
    "code_communes = communes['id'].apply(lambda x: x - CODE_DEP*1000)\n",
    "dvf = dvf[(dvf['Code departement'] == str(CODE_DEP).zfill(2)) & (dvf['Code commune'].isin(code_communes))]\n",
    "dvf = dvf.reset_index(drop=True)\n",
    "\n",
    "# Convert to int\n",
    "columns = ['Code commune', 'Nombre pieces principales', 'Surface reelle bati']\n",
    "dvf[columns] = dvf[columns].astype(int)\n",
    "\n",
    "# Set nombre pieces principales to 5 for all properties with more than 5 rooms\n",
    "index = dvf[dvf['Nombre pieces principales'] >= 5].index\n",
    "dvf.loc[index, 'Nombre pieces principales'] = 5\n",
    "\n",
    "# Remove Nombre de pieces principales = 0\n",
    "dvf = dvf[dvf['Nombre pieces principales'] > 0]\n",
    "\n",
    "dvf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the average size of houses and apartments according to their number of rooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MINIMUM_DATA = 5\n",
    "\n",
    "# Get the average surface for each type of property\n",
    "def get_mean_surface_by_type(df):\n",
    "    # Mean for each combination of 'Nombre pieces principales' and 'Type local'\n",
    "    general_mean = dvf.groupby(['Nombre pieces principales', 'Type local'])['Surface reelle bati'].mean()\n",
    "\n",
    "    # Mean for each combination of 'Code commune', 'Nombre pieces principales' and 'Type local'\n",
    "    mean_by_commune = dvf.groupby(['Code commune', 'Nombre pieces principales', 'Type local'])['Surface reelle bati'].mean()\n",
    "\n",
    "    # Number of data for each combination of 'Code commune', 'Nombre pieces principales' and 'Type local'\n",
    "    count_by_commune = dvf.groupby(['Code commune', 'Nombre pieces principales', 'Type local']).size()\n",
    "\n",
    "    # For combinations where the number of data is less than MINIMUM_DATA, replace with the general mean\n",
    "    for index, count in count_by_commune.items():\n",
    "        if count < MINIMUM_DATA:\n",
    "            commune, n_pieces, local_type = index\n",
    "            mean_by_commune[commune, n_pieces, local_type] = general_mean[n_pieces, local_type]\n",
    "\n",
    "    return mean_by_commune\n",
    "\n",
    "# Get the average surface for each type of property\n",
    "dfs = get_mean_surface_by_type(dvf)\n",
    "dfs = dfs.unstack(level=[1, 2])\n",
    "dfs.columns = [f\"{'H' if col[1][0] == 'M' else col[1][0]}T{col[0]}\" for col in dfs.columns]\n",
    "dfs = dfs.reset_index()\n",
    "\n",
    "# Fill nan with mean values of the column\n",
    "columns = ['AT1', 'HT1', 'AT2', 'HT2', 'AT3', 'HT3', 'AT4', 'HT4', 'AT5', 'HT5']\n",
    "for column in columns:\n",
    "    dfs[column].fillna(dfs[column].mean(), inplace=True)\n",
    "dfs.head()\n",
    "\n",
    "# Add the department code to the city code\n",
    "dfs['Code commune'] = dfs['Code commune'] + CODE_DEP * 1000\n",
    "dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge it to communes to get final df\n",
    "communes = pd.read_json('data/communes-housing.json', orient='records', lines=True)\n",
    "df = pd.merge(left=communes, right=dfs, left_on='id', right_on='Code commune')\n",
    "df = df.drop('Code commune', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('data/communes-surface.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add the price per square meter for each city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "dfc = pd.read_json('data/communes-surface.json', orient='records', lines=True)\n",
    "dfp = pd.read_json('data/price_square_meter.json', lines=True, orient='records')\n",
    "\n",
    "# Merge data\n",
    "df = pd.concat([dfc, dfp.drop('name', axis=1)], axis=1)\n",
    "df.to_json('data/communes-ready.json', orient='records', lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the price of each city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "df = pd.read_json('data/communes-ready.json', orient='records', lines=True)\n",
    "\n",
    "# Count price of one TX for one city\n",
    "def count_price_tx(row, x):\n",
    "    x = str(x) \n",
    "    tx = row['t' + x if int(x) < 5 else 't5+']\n",
    "    a = row['apartment']\n",
    "    h = row['house']\n",
    "    p = row['principal']\n",
    "    ATX = row['AT' + x]\n",
    "    pa = row['price_apart']\n",
    "    HTX = row['HT' + x]\n",
    "    ph = row['price_house']\n",
    "    return tx * ((a/p) * ATX * pa + (h/p) * HTX * ph)\n",
    "\n",
    "# Count price of all TX for one city\n",
    "def count_price(row):\n",
    "    sum = 0\n",
    "    for i in range(1, 6):\n",
    "        sum += count_price_tx(row, i)\n",
    "    return sum\n",
    "\n",
    "# Count price for all cities\n",
    "df['city_price'] = df.apply(count_price, axis=1)\n",
    "df.to_json('data/communes-price.json', orient='records', lines=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add GeoJSON cadastre to each city "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Load GeoJSON file with geopandas\n",
    "gdf = gpd.read_file('data/cadastre-33-communes.json')\n",
    "gdf.drop(['nom', 'created', 'updated'], axis=1, inplace=True)\n",
    "gdf['id'] = gdf['id'].astype('int')\n",
    "\n",
    "# Load JSON file with pandas\n",
    "df = pd.read_json('data/communes-price.json', orient='records', lines=True)\n",
    "\n",
    "# Merge GeoJSON and JSON files\n",
    "gdf = gdf.merge(df, on='id', how='right')\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import numpy as np\n",
    "\n",
    "MIN_PRICE = np.log(min(gdf['city_price']))\n",
    "MAX_PRICE = np.log(max(gdf['city_price']))\n",
    "\n",
    "# Define the style of each location\n",
    "def style_function(feature):\n",
    "\n",
    "    # Définir la couleur de remplissage en fonction du log du prix \n",
    "    min_opacity = 0.05\n",
    "    max_opacity = 0.5\n",
    "    opacity = min_opacity + (max_opacity - min_opacity) * (np.log(feature['properties']['city_price']) - MIN_PRICE) / (MAX_PRICE - MIN_PRICE)\n",
    "\n",
    "\n",
    "    return {\n",
    "        'fillColor': '#ff0000',   # couleur de remplissage\n",
    "        'color': f'rgba(255, 0, 0, {opacity})',      # couleur de la ligne\n",
    "        'weight': 1,             # épaisseur de la ligne\n",
    "        'fillOpacity': opacity,       # opacité du remplissage\n",
    "        'clickable': False,       # si True, la zone réagit au clic\n",
    "\n",
    "    }\n",
    "\n",
    "# Rewrite price to readable format\n",
    "def format_price(price):\n",
    "    d = {\n",
    "        1000000000: 'B€',\n",
    "        1000000: 'M€',\n",
    "        1000: 'K€',\n",
    "    }\n",
    "    for k in d:\n",
    "        if price > k:\n",
    "            return f'{round(price / k, 1)}{d[k]}'\n",
    "    return price\n",
    "\n",
    "\n",
    "# Define a custom function to create the tooltip (hover popup)\n",
    "tooltip = folium.GeoJsonTooltip(\n",
    "    fields=['name'], \n",
    "    sticky=False\n",
    ")\n",
    "\n",
    "# Créer une carte centrée sur les coordonnées moyennes du GeoDataFrame\n",
    "m = folium.Map(\n",
    "    location=[gdf.geometry.unary_union.centroid.y, gdf.geometry.unary_union.centroid.x],\n",
    "    zoom_start=10,\n",
    "    tiles='https://cartodb-basemaps-{s}.global.ssl.fastly.net/light_nolabels/{z}/{x}/{y}.png',\n",
    "    attr='&copy; <a href=\"https://www.openstreetmap.org/copyright\">OpenStreetMap</a> contributors &copy; <a href=\"https://carto.com/attributions\">CARTO</a>'\n",
    ")\n",
    "\n",
    "# Add the data to the map with folium\n",
    "folium.GeoJson(\n",
    "    gdf, \n",
    "    style_function=style_function,\n",
    "    tooltip=tooltip\n",
    ").add_to(m)\n",
    "\n",
    "# 2. Add names centered on each location\n",
    "for _, row in gdf.iterrows():\n",
    "    location = [row['geometry'].centroid.y, row['geometry'].centroid.x]\n",
    "    folium.Marker(location, icon=folium.DivIcon(\n",
    "        html=f\"\"\"\n",
    "            <div style=\"font-family: 'Arial', sans-serif; transform: translate(-50%, -50%);\">\n",
    "                {row['name']}\n",
    "                {format_price(row['city_price'])}\n",
    "            </div>\n",
    "        \"\"\"\n",
    "    )).add_to(m)\n",
    "\n",
    "# Afficher la carte\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PRICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[gdf['apartment'] + gdf['house'] != gdf['housing']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
